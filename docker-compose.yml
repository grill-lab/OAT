version: "3.9"  # optional since v1.27.0
services:

  builder:
    container_name: bob
    build:
      context: ./
      dockerfile: builder/Dockerfile
    volumes:
      - ./builder:/source
      - ./shared:/shared

  downloader:
    container_name: downloader
    profiles: ["downloader"]
    build:
      context: ./
      dockerfile: downloader/Dockerfile
    volumes:
      - ./shared:/shared
      - ./downloader:/source
      # services which have downloads.toml at the moment
      - ./offline:/offline
      - ./llm_functionalities:/llm_functionalities
      - ./neural_functionalities:/neural_functionalities
      - ./functionalities:/functionalities
      - ./training:/training
    environment:
      - CONTAINER_NAME=downloader
    depends_on:
      - builder
      - oat_common
    networks:
      - internal
      - external

  local_client:
    container_name: local_client
    build:
      context: ./
      dockerfile: local_client/Dockerfile
    ports:
      - "9000:8000"
    volumes:
      - ./local_client:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=local_client
      - DISTRIBUTOR_URL=http://orchestrator:8000
    networks:
      - internal
      - external
    depends_on:
      - builder
      - oat_common

  oat_common:
    container_name: oat_common
    build:
      context: ./
      dockerfile: oat_common/Dockerfile
    image: oat_common

  orchestrator:
    container_name: orchestrator
    build:
      context: ./
      dockerfile: orchestrator/Dockerfile
    volumes:
      - ./orchestrator:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=orchestrator
      - FUNCTIONALITIES_URL=functionalities:8000
      - EXTERNAL_FUNCTIONALITIES_URL=external_functionalities:8000
      - NEURAL_FUNCTIONALITIES_URL=neural_functionalities:8000
      - LLM_FUNCTIONALITIES_URL=llm_functionalities:8000
    networks:
      - internal
    depends_on:
      - builder
      - oat_common
      - functionalities
      - external_functionalities
      - neural_functionalities

  functionalities:
    container_name: functionalities
    build:
      context: ./
      dockerfile: functionalities/Dockerfile
    volumes:
      - ./functionalities:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=functionalities
      - EXTERNAL_FUNCTIONALITIES_URL=external_functionalities:8000
      - FUNCTIONALITIES_URL=functionalities:8000
      - NEURAL_FUNCTIONALITIES_URL=neural_functionalities:8000
      - LLM_FUNCTIONALITIES_URL=llm_functionalities:8000
    networks:
      - internal
      - external
    depends_on:
      - builder
      - oat_common

  external_functionalities:
    container_name: external_functionalities
    build:
      context: ./
      dockerfile: external_functionalities/Dockerfile
    volumes:
      - ./external_functionalities:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=external_functionalities
      - DATABASE_URL=http://dynamodb-local:8000
      - FUNCTIONALITIES_URL=functionalities:8000
    networks:
      - internal
      - external
    depends_on:
      - builder
      - oat_common
      - dynamodb-local

  neural_functionalities:
    container_name: neural_functionalities
    build:
      context: ./
      dockerfile: neural_functionalities/Dockerfile
    volumes:
      - ./neural_functionalities:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=neural_functionalities
      - NEURAL_FUNCTIONALITIES_URL=neural_functionalities:8000
      - FUNCTIONALITIES_URL=functionalities:8000
      - EXTERNAL_FUNCTIONALITIES_URL=external_functionalities:8000
    networks:
      - internal
      - external
    depends_on:
      builder:
        condition: service_started
      oat_common:
        condition: service_started


  dynamodb-local:
    container_name: dynamodb-local
    image: "amazon/dynamodb-local:latest"
    ports:
      - "8888:8000"
    volumes:
      - "./shared/file_system/dynamodb:/home/dynamodblocal/data"
    working_dir: /home/dynamodblocal
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
    user: root
    networks:
      - internal
      - external

  dashboard:
    container_name: dashboard
    profiles: ["dashboard"]
    build:
      context: ./
      dockerfile: dashboard/Dockerfile
    ports:
      - "7500:7500"
    volumes:
      - ./dashboard:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=dashboard
      - DB_ENVIRONMENT=Undefined
      - DATABASE_URL=http://dynamodb-local:8000
    networks:
      - internal
      - external
    depends_on:
      - builder
      - dynamodb-local
      - oat_common

  tester:
    container_name: tester
    profiles: ["tester"]
    build:
      context: ./
      dockerfile: tester/Dockerfile
    volumes:
      - ./tester:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=tester
      - FUNCTIONALITIES_URL=functionalities:8000
      - EXTERNAL_FUNCTIONALITIES_URL=external_functionalities:8000
      - NEURAL_FUNCTIONALITIES_URL=neural_functionalities:8000
      - DISTRIBUTOR_URL=http://orchestrator:8000
    networks:
      - external
      - internal
    depends_on:
      - builder
      - oat_common

  offline:
    container_name: offline
    profiles: ["offline"]
    build:
      context: ./
      dockerfile: offline/Dockerfile
    volumes:
      - ./offline:/source
      - ./shared:/shared
      - ./testing/integration_tests:/integration_tests
    environment:
      - CONTAINER_NAME=offline
      - FUNCTIONALITIES_URL=functionalities:8000
    networks:
      - internal
      - external
    depends_on:
      - oat_common
      - dynamodb-local
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]


  sphinx_docs:
    container_name: sphinx_docs
    profiles: ["sphinx_docs"]
    build:
      context: ./
      dockerfile: sphinx_docs/Dockerfile
    volumes:
      # this is a bit different from the other containers in that it mounts
      # the entire OAT folder at /source. this allows Sphinx to have
      # access to the entire codebase instead of a subfolder
      - ./:/source
      # shared is accessible through the /source mount, but to make the paths
      # work as expected mount it separately too
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=sphinx_docs
    depends_on:
      - builder

  training:
    container_name: training
    profiles: ["training"]
    build:
      context: ./
      dockerfile: training/Dockerfile
    volumes:
      - ./training:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=training
    networks:
      - internal
      - external
    depends_on:
      - builder
      - oat_common
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  llm_functionalities:
    container_name: llm_functionalities
    build:
      context: ./
      dockerfile: llm_functionalities/Dockerfile
    volumes:
      - ./llm_functionalities:/source
      - ./shared:/shared
    environment:
      - CONTAINER_NAME=llm_functionalities
      - NEURAL_FUNCTIONALITIES_URL=llm_functionalities:8000
      - FUNCTIONALITIES_URL=functionalities:8000
      - EXTERNAL_FUNCTIONALITIES_URL=external_functionalities:8000
    networks:
      - internal
      - external
    depends_on:
      builder:
        condition: service_started
      oat_common:
        condition: service_started
  tgi:
    platform: linux/x86_64
    container_name: tgi
    build:
      context: ./
      dockerfile: hg_tgi/Dockerfile
    volumes:
      # the container downloads weights and other files to this path
      - ./shared/file_system/tgi:/data
    environment:
      - MODEL_ID=google/flan-t5-base
    networks:
      - internal
      - external
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

networks:
  internal:
    internal: true
  external:
    internal: false

